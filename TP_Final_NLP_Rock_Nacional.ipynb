{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento Lenguaje Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Debate cultural en el Rock Nacional*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe una asociación entre Rock Nacional Argentino, entendido como fenómeno contracultural de identificación juvenil y la busca de una expresión popular que refleje la situación coyuntural del país. El objetivo de este trabajo consiste en analizar la estrecha relación existente entre la construcción discursiva que tematizan las principales líricas del Rock Argentino con los hitos históricos sucedidos en dicho país en el transcurso de los años 1970-2010. Para poder llevar a cabo la investigación, se utilizó como corpus de más de 1000 artistas y un total superior a 24.000 canciones, extraídas del sitio web (www.rock.com.ar). \n",
    "El foco principal del estudio consistió en evaluar los tópicos presentes en las canciones tanto como la impronta sentimental en las mismas, haciendo especial énfasis en los cambios en las temáticas de interés a través de las décadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias basicas\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from pandas.core.common import flatten\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from datetime import datetime\n",
    "\n",
    "#Librerias para scrapping\n",
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "from bs4 import BeautifulSoup,SoupStrainer\n",
    "\n",
    "# Librerias para NLP\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import nltk\n",
    "from nltk import stem\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer,SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Plotting tools\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from wordcloud import WordCloud\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Varias\n",
    "import warnings\n",
    "from IPython.display import Markdown, display\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Función que busca el path de las encliclopedias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buscamos las enciclopedias\n",
    "def get_enciclopedias(URL):\n",
    "    r = requests.get(URL)\n",
    "    html = r.content.decode('utf-8')\n",
    "    bhtml = bs4.BeautifulSoup(html)\n",
    "    enciclopedia = []\n",
    "    for link in bhtml.find_all('a', attrs={'href': re.compile(\"^/enciclopedia\")}):\n",
    "        enciclopedia.append(link.get('href'))\n",
    "    del enciclopedia[0]\n",
    "    return enciclopedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Función que busca el path de los artistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buscamos los artistas dentro de cada enciclopedia\n",
    "def get_artistas(URL):\n",
    "    r = requests.get(URL)\n",
    "    html = r.content.decode('utf-8')\n",
    "    bhtml = bs4.BeautifulSoup(html)\n",
    "    artista = []\n",
    "    for link in bhtml.find_all('a', attrs={'href': re.compile(\"^/artista\")}):\n",
    "            artista.append(link.get('href'))\n",
    "    return artista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Función que scrapea la metadata y el path de las canciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bandas(artista):\n",
    "    # Variables\n",
    "    nombre_artista = [] ; path_discos = [] ; fecha_edicion = [] ; canciones = [[],[],[],[]] \n",
    "    # Get de url\n",
    "    disc_url = 'https://www.rock.com.ar' + artista + '/discos'\n",
    "    r = requests.get(disc_url)\n",
    "    html = r.content.decode('utf-8') ; bhtml = bs4.BeautifulSoup(html)\n",
    "    # Links a los Discos\n",
    "    for link in bhtml.find_all('a', attrs={'href': re.compile(\"^\" + artista + \"/discos\")}):\n",
    "        path_discos.append(link.get('href'))\n",
    "    path_discos = path_discos[1:-1]\n",
    "    path_discos = np.unique(path_discos)             \n",
    "    # Discos-Fecha-Canciones de las canciones en cada Disco\n",
    "    for i in range(len(path_discos)):\n",
    "        # Get de url\n",
    "        disc_url = 'https://www.rock.com.ar' + path_discos[i]\n",
    "        r = requests.get(disc_url)\n",
    "        html = r.content.decode('utf-8') ; bhtml = bs4.BeautifulSoup(html)\n",
    "        #Artista\n",
    "        nombre_artista = bhtml.find('h1').text\n",
    "        #Año publicacion\n",
    "        fecha_edicion= bhtml.find_all(re.compile('^p'))[1].text\n",
    "        fecha_edicion = fecha_edicion.split(':')[1]\n",
    "        if len(fecha_edicion.split('/')) != 1:\n",
    "            fecha_edicion = fecha_edicion.split('/')[2]\n",
    "        #Disco y canciones\n",
    "        for link in bhtml.find_all('a', attrs={'href': re.compile(\"^\"+'/'.join(path_discos[i].split('/')[0:3]) + '/letras')}):\n",
    "            if len(link.get('href').split('/'))>4:\n",
    "                canciones[0].append(nombre_artista)                \n",
    "                canciones[1].append(path_discos[i])\n",
    "                canciones[2].append(fecha_edicion)\n",
    "                canciones[3].append(link.get('href'))\n",
    "    return canciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Función que busca las letras de las canciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Te devuelve el corpus de las liricas de las canciones\n",
    "def get_liricas(URL):\n",
    "    r = requests.get(URL)\n",
    "    html = r.content.decode('utf-8')\n",
    "    bhtml = bs4.BeautifulSoup(html)\n",
    "    letras = bhtml.find('div', attrs={'class':'post-content-text'})\n",
    "    letras = letras.get_text()\n",
    "    liricas = re.split('\\n\\n',letras)[3]\n",
    "    return liricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Función que limpa el texto de las canciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_cancion(cancion):\n",
    "    cancion = str(cancion)\n",
    "    cancion = cancion.replace(\".\", \" \")                             # Reemplazamos puntos por espacios\n",
    "    cancion = re.sub(\"\\d+\", \" \", cancion)                           # Eliminamos de caracteres numericos.\n",
    "    cancion = cancion.replace('\\n', ' ')                            # Eliminamos salto de parrafo.\n",
    "    cancion = cancion.replace('\\r', ' ')                            # Eliminamos de nuevas lineas.\n",
    "    cancion = cancion.translate(str.maketrans(\"\", \"\", punctuation)) # Eliminamos caracteres de puntuacion ( !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ ).\n",
    "    cancion = re.sub('([A-Z])', r' \\1', cancion)                    # Espacio antes de mayusculas \n",
    "    cancion = cancion.lower()                                       # Convertimos a minuscula.\n",
    "    cancion = re.sub(\"  +\", \" \", cancion)                           # Eliminamos mas de 2 espacios\n",
    "    return cancion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Función que normaliza el texto de las canciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "def normalizar_cancion(cancion):\n",
    "    doc = nlp(cancion)\n",
    "    words = [t.orth_ for t in doc if not t.is_punct | t.is_stop] # Crea una lista de tokens sacando stopwords\n",
    "    tokens = [t for t in words if len(t) > 3] #Eliminamos tokens con menos de 3 letras\n",
    "    lemmas = []\n",
    "    for i in range(len(tokens)):\n",
    "        doc = nlp(tokens[i])\n",
    "        lemmas.append([w.lemma_ for w in doc])    \n",
    "    return list(flatten(lemmas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escrapeamos las enciclopedias en busqueda de los artistas con sus discografía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.rock.com.ar/'\n",
    "enciclopedia = [] ; artista = [] ; banda_rock = []\n",
    "enciclopedia = get_enciclopedias(URL)\n",
    "for i in tqdm(range(len(enciclopedia)-1)):\n",
    "    URL = 'https://www.rock.com.ar' + enciclopedia[i]\n",
    "    artista = get_artistas(URL)\n",
    "    seleccion = random.sample(artista,math.floor(len(artista)*1))\n",
    "    for j in range(len(seleccion)):\n",
    "        banda_rock.append(get_bandas(seleccion[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos las listas a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Artista','Path_disco','Fecha_edicion','Path_canciones'])\n",
    "for n in range(len(banda_rock)):\n",
    "    df_temp = pd.DataFrame(columns=['Artista','Path_disco','Fecha_edicion','Path_canciones'])\n",
    "    df_temp = pd.DataFrame(banda_rock[n]).T\n",
    "    df_temp.columns = ['Artista','Path_disco','Fecha_edicion','Path_canciones']\n",
    "    frames = [df,df_temp]\n",
    "    if len(df_temp)>0 : df = pd.concat(frames,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos a que decada pertenece cada cancion y buscamos su lirica (letra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion de decada\n",
    "trunc = lambda x: math.trunc(x/10) * 10\n",
    "Decada = pd.to_numeric(df.Fecha_edicion).map(trunc)\n",
    "df.insert(3, \"Decada\", Decada)\n",
    "# Busqueda de lirica\n",
    "for i in tqdm(range(len(df))):\n",
    "    URL = 'https://www.rock.com.ar' + df.Path_canciones[i]\n",
    "    df.loc[df['Path_canciones']==df.Path_canciones[i],'Liricas']=get_liricas(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección realizaremos la limpieza y normalizacion del corpus de las canciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de caracteres no deseados en el corpus\n",
    "df.Liricas = df.Liricas.apply(limpiar_cancion)\n",
    "# Normalizacion del corpus\n",
    "df.Liricas = df.Liricas.apply(normalizar_cancion)\n",
    "# Eliminacion de canciónes repetidas (presentes en mas de un disco)\n",
    "df = df.sort_values(\"Fecha_edicion\")\n",
    "df = df.drop_duplicates(subset=\"Path_canciones\", keep=\"first\")\n",
    "df = df.drop_duplicates(subset=\"Liricas\", keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportamos el dataset a una base de datos para tener la información almacenada localmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"BD_Rock_Nacional.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Models & Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos la base de datos\n",
    "df = pd.read_csv(\"BD_Rock_Nacional.csv\")\n",
    "# Reconversión de las Liricas a Tokens (str por el csv)\n",
    "tokens = df.Liricas\n",
    "tokens = [n.strip('][').split(', ') for n in tokens]\n",
    "tokens = [[x.replace(\"'\", \"\") for x in i] for i in tokens]\n",
    "df.insert(6,\"Tokens\",tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen_fecha = df.groupby(['Fecha_edicion']).agg(['nunique','count'])\n",
    "fig,(ax1,ax3) = plt.subplots(1,2,figsize=(30,10))\n",
    "fig.suptitle('Canciones y Artistas por año/decada', fontsize=35)\n",
    "ax1.plot(resumen_fecha.index,resumen_fecha.iloc[:,0], color=\"red\", marker=\"o\")\n",
    "ax1.set_xlabel(\"Fecha_edicion\",fontsize=20)\n",
    "ax1.set_ylabel(\"Artistas\",color=\"red\",fontsize=20)\n",
    "plt.grid(True)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(resumen_fecha.index,resumen_fecha.iloc[:,5],color=\"blue\",marker=\"o\")\n",
    "resumen_decada = df.groupby(['Decada']).agg(['nunique','count'])\n",
    "ax3.plot(resumen_decada.index,resumen_decada.iloc[:,0], color=\"red\", marker=\"o\")\n",
    "ax3.set_xlabel(\"Decada\",fontsize=20)\n",
    "plt.grid(True)\n",
    "ax4 = ax3.twinx()\n",
    "ax4.plot(resumen_decada.index,resumen_decada.iloc[:,5],color=\"blue\",marker=\"o\")\n",
    "ax4.set_ylabel(\"Canciones\",color=\"blue\",fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un pareto para conocer los artistas más influyentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen_artista = df.groupby(['Artista']).count()\n",
    "resumen_artista = resumen_artista.sort_values(\"Liricas\",ascending=False)\n",
    "resumen_artista[\"cumpercentage\"] = resumen_artista[\"Liricas\"].cumsum()/resumen_artista[\"Liricas\"].sum()*100\n",
    "pareto = len(resumen_artista.loc[resumen_artista[\"cumpercentage\"]<=80]) / len(resumen_artista)\n",
    "print(\"El\",round(pareto*100),\"% de los artistas compuso el 80% del total de las canciones de la base de datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los 40 principales artistas de la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = resumen_artista.iloc[0:40,:]\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "fig.suptitle('Los 40 principales', fontsize=35)\n",
    "ax.bar(top.index, top[\"Liricas\"], color=\"C0\")\n",
    "plt.xticks(rotation=90,fontsize=15)\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(top.index, top[\"cumpercentage\"], color=\"C1\", marker=\"D\", ms=7)\n",
    "ax2.yaxis.set_major_formatter(PercentFormatter())\n",
    "ax.tick_params(axis=\"y\", colors=\"C0\")\n",
    "ax2.tick_params(axis=\"y\", colors=\"C1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wordcloud por decada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sacar_comilla(cancion):\n",
    "    cancion = cancion.replace(\"'\", \"\")      # Eliminamos comillas para mejor interpretacion\n",
    "    return cancion\n",
    "Words = pd.DataFrame(df.Tokens.astype(str).apply(sacar_comilla))\n",
    "Words.insert(0,\"Decada\",df.Decada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canciones_70 = ''.join([str(n) for n in Words[Words['Decada']==1970]['Tokens']])\n",
    "canciones_70_wc = WordCloud(background_color=\"white\",colormap=\"Dark2\",max_font_size=100,random_state=15,width=512, height=512).generate(canciones_70)\n",
    "canciones_80 = ''.join([str(n) for n in Words[Words['Decada']==1980]['Tokens']])\n",
    "canciones_80_wc = WordCloud(background_color=\"white\",colormap=\"Dark2\",max_font_size=100,random_state=15,width=512, height=512).generate(canciones_80)\n",
    "canciones_90 = ''.join([str(n) for n in Words[Words['Decada']==1990]['Tokens']])\n",
    "canciones_90_wc = WordCloud(background_color=\"white\",colormap=\"Dark2\",max_font_size=100,random_state=15,width=512, height=512).generate(canciones_90)\n",
    "canciones_00 = ''.join([str(n) for n in Words[Words['Decada']==2000]['Tokens']])\n",
    "canciones_00_wc = WordCloud(background_color=\"white\",colormap=\"Dark2\",max_font_size=100,random_state=15,width=512, height=512).generate(canciones_00)\n",
    "fig, ax = plt.subplots(2,2, figsize = (20,20))\n",
    "ax[0,0].imshow(canciones_70_wc)\n",
    "ax[0,0].axis('off')\n",
    "ax[0,0].set_title('Decada 1970s', fontsize = 30)\n",
    "ax[0,1].imshow(canciones_80_wc)\n",
    "ax[0,1].axis('off')\n",
    "ax[0,1].set_title('Decada 1980s', fontsize = 30)\n",
    "ax[1,0].imshow(canciones_90_wc)\n",
    "ax[1,0].axis('off')\n",
    "ax[1,0].set_title('Decada 1990s', fontsize = 30)\n",
    "ax[1,1].imshow(canciones_00_wc)\n",
    "ax[1,1].axis('off')\n",
    "ax[1,1].set_title('Decada 2000', fontsize = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evolución de las palabras a través de los años"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Words70 = pd.DataFrame(canciones_70_wc.words_.items(), columns=['Palabra', '1970s']).iloc[0:10]\n",
    "Words80 = pd.DataFrame(canciones_80_wc.words_.items(), columns=['Palabra', '1980s']).iloc[0:10]\n",
    "Words90 = pd.DataFrame(canciones_90_wc.words_.items(), columns=['Palabra', '1990s']).iloc[0:10]\n",
    "Words00 = pd.DataFrame(canciones_00_wc.words_.items(), columns=['Palabra', '2000s']).iloc[0:10]\n",
    "Topwords10 = Words70.merge(Words80,on='Palabra',how='outer').merge(Words90,on='Palabra',how='outer').merge(Words00,on='Palabra',how='outer')\n",
    "freq70 = pd.DataFrame(canciones_70_wc.words_.items(), columns=['Palabra', '1970s']).iloc[0:100]\n",
    "freq80 = pd.DataFrame(canciones_80_wc.words_.items(), columns=['Palabra', '1980s']).iloc[0:100]\n",
    "freq90 = pd.DataFrame(canciones_90_wc.words_.items(), columns=['Palabra', '1990s']).iloc[0:100]\n",
    "freq00 = pd.DataFrame(canciones_00_wc.words_.items(), columns=['Palabra', '2000s']).iloc[0:100]\n",
    "Topwords100 = freq70.merge(freq80,on='Palabra',how='outer').merge(freq90,on='Palabra',how='outer').merge(freq00,on='Palabra',how='outer')\n",
    "Topwords10 = pd.DataFrame(Topwords10['Palabra'])\n",
    "Topwords10 = Topwords10.merge(Topwords100 ,on='Palabra',how='left')\n",
    "Topwords10 = Topwords10.set_index('Palabra')\n",
    "Topwords10 = Topwords10.transpose()\n",
    "Topwords10 = Topwords10.replace(np.nan, 0)\n",
    "# Subset de palabras\n",
    "Topwords = pd.DataFrame(Topwords10[[\"vivir\",\"pensar\",\"morir\",\"esperar\",\"mundo\",\"vida\",\"sentir\",\"noche\",\"decir\",\"corazón\"]])\n",
    "plt.figure()\n",
    "Topwords.plot(subplots=True, layout=(15, 5), figsize=(20, 30))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Models (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Número óptimo de tópicos en función de la Coherencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para evaluar el número óptimo de Tópicos según la Coherencia\n",
    "def learn_lda_model(corpus, dictionary, texts,k):\n",
    "    lda = LdaModel(corpus, \n",
    "               id2word=dictionary, \n",
    "               num_topics=k, \n",
    "               random_state=37, \n",
    "               iterations=100,\n",
    "               passes=5,\n",
    "               per_word_topics=False)\n",
    "    cm = CoherenceModel(model=lda, corpus=corpus, texts=texts, coherence='c_v') \n",
    "    coherence = cm.get_coherence()\n",
    "    print('{}: {}'.format(k, coherence))\n",
    "    return k, coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Liricas = df.Tokens\n",
    "dictionary = corpora.Dictionary(Liricas)\n",
    "corpus = [dictionary.doc2bow(text) for text in Liricas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_scores = [learn_lda_model(corpus, dictionary, Liricas,k) for k in tqdm(range(2, 15))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(scores, ax, ylabel):\n",
    "    _x = [s[0] for s in scores]\n",
    "    _y = [s[1] for s in scores]\n",
    "    ax.plot(_x, _y, color='tab:blue')\n",
    "    ax.set_xlabel('k')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title('{} vs k'.format(ylabel))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "plot_scores(lda_scores, ax, 'LDA Coherence')\n",
    "plt.axvline(x=5,color=\"red\",linestyle=\"dashed\")\n",
    "plt.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Topic Models ( k = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOPICS = 5 #max(lda_scores,key=itemgetter(1))[0]\n",
    "\n",
    "# LDA\n",
    "common_texts = Liricas\n",
    "# Create a corpus from a list of texts\n",
    "id2word = Dictionary(common_texts)\n",
    "corpus = [id2word.doc2bow(text) for text in common_texts]\n",
    "\n",
    "# # Train the model on the corpus.\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=N_TOPICS, \n",
    "                                           random_state=100,\n",
    "                                            update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_display = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asignación del tópico correspondiente a cada canción, siendo este el de mayor probabilidad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs = []\n",
    "for i in range(len(Liricas)):\n",
    "    top_topics = lda_model.get_document_topics(corpus[i], minimum_probability=0.0)\n",
    "    topic_vec = [top_topics[i][1] for i in range(N_TOPICS)]\n",
    "    train_vecs.append(topic_vec)\n",
    "train_vecs = pd.DataFrame(train_vecs)\n",
    "df['Topic'] = train_vecs.idxmax(axis=1, skipna=True)\n",
    "df['Topic_proba'] = train_vecs.max(axis=1)\n",
    "df[df['Topic'] == 0].nlargest(5,\"Topic_proba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construcción Lexicon en Español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx = pd.read_excel(\"NRC-Emotion-Lexicon-v0.92-In105Languages-Nov2017Translations.xlsx\")\n",
    "xlsx = xlsx[['Spanish (es)','Positive','Negative','Anger','Anticipation','Disgust','Fear','Joy','Sadness','Surprise','Trust']]\n",
    "xlsx.columns = ['Español','Positivo','Negativo','Enojo','Esperanza','Asco','Miedo','Alegria','Tristeza','Sorpresa','Confianza']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_iterate = ['Positivo','Negativo','Enojo','Esperanza','Asco','Miedo','Alegria','Tristeza','Sorpresa','Confianza']\n",
    "with open('lexicon_spanish_2020.txt', 'a') as f:\n",
    "    for index, a_word in xlsx.iterrows():\n",
    "        for a_column in columns_to_iterate:\n",
    "            line = \"%s\\t%s\\t%d\\n\" % (a_word['Español'], a_column, a_word[a_column])\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análisis de Emociones y Sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las herramientas a utilizar\n",
    "from py_lex import Liwc, EmoLex\n",
    "lexicon = EmoLex('lexicon_spanish_2020.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos las columnas con los sentimientos\n",
    "df['Positivo'] = 0.0\n",
    "df['Negativo'] = 0.0\n",
    "df['Enojo'] = 0.0\n",
    "df['Asco'] = 0.0\n",
    "df['Miedo'] = 0.0\n",
    "df['Tristeza'] = 0.0\n",
    "df['Alegria'] = 0.0\n",
    "df['Sorpresa'] = 0.0\n",
    "df['Confianza'] = 0.0\n",
    "df['Esperanza'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos el grado de probabilidad que posee sobre las sentimientos / emociones definidas\n",
    "for index, _ in df.iterrows():\n",
    "    try:\n",
    "        summary = lexicon.summarize_doc(df[\"Tokens\"][index])\n",
    "        for key in summary.keys():\n",
    "            df.at[index, key] = summary[key]\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Asignación de Sentimientos / Emociones y Tópicos a las canciones\n",
    "Definimos el sentimiento que representa cada canción (criterio de mayor probabilidad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.iloc[:,0:9]\n",
    "#Sentimientos\n",
    "df_final[\"Sentimiento\"]= df[['Positivo','Negativo']].idxmax(axis=\"columns\", skipna=True)\n",
    "df_final[\"Sentimiento_proba\"]= df[['Positivo','Negativo']].max(axis=1)\n",
    "#Emociones\n",
    "df_final[\"Emocion\"]= df[['Enojo','Asco','Miedo','Tristeza','Alegria','Sorpresa','Confianza','Esperanza']].idxmax(axis=\"columns\", skipna=True)\n",
    "df_final[\"Emocion_proba\"]= df[['Enojo','Asco','Miedo','Tristeza','Alegria','Sorpresa','Confianza','Esperanza']].max(axis=1)\n",
    "# Eliminamos los NAN\n",
    "df_final = df_final.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asignamos los nombres / etiquetas a los topicos encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"Topic\"] = df_final[\"Topic\"].replace(0,\"Esperanza\")\n",
    "df_final[\"Topic\"] = df_final[\"Topic\"].replace(1,\"Ingles\")\n",
    "df_final[\"Topic\"] = df_final[\"Topic\"].replace(2,\"Festividad\")\n",
    "df_final[\"Topic\"] = df_final[\"Topic\"].replace(3,\"Romanticismo\")\n",
    "df_final[\"Topic\"] = df_final[\"Topic\"].replace(4,\"Violencia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos la base de datos con los topicos y sentimientos\n",
    "df_final = pd.read_csv(\"Rock_Nacional_Final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emociones\n",
    "Negativas durante la decada 70-90s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desde = 1970 ; hasta = 1990\n",
    "df_final.loc[df_final[\"Decada\"].isin(range(desde,hasta)) & df_final[\"Emocion\"].isin([\"Miedo\",\"Enojo\",\"Tristeza\"])].pivot_table(index='Fecha_edicion',columns='Emocion',values='Liricas',aggfunc=len, fill_value=0).plot(figsize=(30,10))\n",
    "# Hitos históricos de la Argentia\n",
    "plt.axvline(1975,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Rodrigazo\n",
    "plt.text(1975,0,\"Rodrigazo\",fontsize=20,color=\"black\",rotation=90)\n",
    "plt.axvline(1976,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Dictadura\n",
    "plt.text(1976,0,\"Dictadura\",fontsize=20,color=\"black\",rotation=90)\n",
    "plt.axvline(1978,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Mundial\n",
    "plt.text(1978,0,\"Mundial\",fontsize=20,color=\"black\",rotation=90)\n",
    "plt.axvline(1982,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Guerra de las Malvinas\n",
    "plt.text(1982,0,\"Guerra de las Malvinas\",fontsize=20,color=\"black\",rotation=90)       \n",
    "plt.axvline(1983,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Vuelta de la democracia\n",
    "plt.text(1983,0,\"Vuelta de la Democracia\",fontsize=20,color=\"black\",rotation=90)      \n",
    "plt.axvline(1989,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Hiperinflación\n",
    "plt.text(1989,0,\"Hiperinflación\",fontsize=20,color=\"black\",rotation=90)               \n",
    "#plt.axvline(2001,color=\"grey\",linewidth=4,linestyle=\"dashed\")          # Crisis del 2001\n",
    "#plt.text(2001,0,\"Crisis 2001\",fontsize=20,color=\"black\",rotation=90)                  \n",
    "plt.title(\"Emociones negativas desde %s\" % desde + \" hasta %s\" % hasta,fontsize=35)\n",
    "plt.xlabel(\"Fecha de edición\", fontsize=20)\n",
    "plt.ylabel(\"# Canciones\", fontsize=20)\n",
    "plt.xlim(desde,hasta)\n",
    "plt.xticks(ticks=range(desde,hasta),fontsize=20,rotation=90)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.legend(fontsize=25,loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positivas decada 70-90s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desde = 1970 ; hasta = 1990\n",
    "df_final.loc[df_final[\"Decada\"].isin(range(desde,hasta)) & df_final[\"Emocion\"].isin(['Alegria','Confianza','Esperanza'])].pivot_table(index='Fecha_edicion',columns='Emocion',values='Liricas',aggfunc=len, fill_value=0).plot(figsize=(30,10))\n",
    "#Hitos históricos de la Argentia\n",
    "plt.axvline(1975,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Rodrigazo\n",
    "plt.text(1975,0,\"Rodrigazo\",fontsize=20,color=\"black\",rotation=90)\n",
    "plt.axvline(1976,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Dictadura\n",
    "plt.text(1976,0,\"Dictadura\",fontsize=20,color=\"black\",rotation=90)\n",
    "plt.axvline(1978,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Mundial\n",
    "plt.text(1978,0,\"Mundial\",fontsize=20,color=\"black\",rotation=90)\n",
    "plt.axvline(1982,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Guerra de las Malvinas\n",
    "plt.text(1982,0,\"Guerra de las Malvinas\",fontsize=20,color=\"black\",rotation=90)       \n",
    "plt.axvline(1983,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Vuelta de la democracia\n",
    "plt.text(1983,0,\"Vuelta de la Democracia\",fontsize=20,color=\"black\",rotation=90)      \n",
    "plt.axvline(1989,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Hiperinflación\n",
    "plt.text(1989,0,\"Hiperinflación\",fontsize=20,color=\"black\",rotation=90)               \n",
    "#plt.axvline(2001,color=\"grey\",linewidth=4,linestyle=\"dashed\")          # Crisis del 2001\n",
    "#plt.text(2001,0,\"Crisis 2001\",fontsize=20,color=\"black\",rotation=90)                  \n",
    "plt.title(\"Emociones postivas desde %s\" % desde + \" hasta %s\" % hasta,fontsize=35)\n",
    "plt.xlabel(\"Fecha de edición\", fontsize=20)\n",
    "plt.ylabel(\"# Canciones\", fontsize=20)\n",
    "plt.xlim(desde,hasta)\n",
    "plt.xticks(ticks=range(desde,hasta),fontsize=20,rotation=90)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.legend(fontsize=25,loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topicos \n",
    "Decada 1970-90s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desde = 1970 ; hasta = 1990\n",
    "df_final.loc[df_final[\"Decada\"].isin(range(desde,hasta)) & df_final[\"Topic\"].isin([\"Esperanza\",\"Festividad\",\"Romanticismo\",\"Violencia\"])].pivot_table(index='Fecha_edicion',columns='Topic',values='Liricas',aggfunc=len, fill_value=0).plot(figsize=(30,10))\n",
    "#Hitos históricos de la Argentia\n",
    "plt.axvline(1975,color=\"grey\",linewidth=4,linestyle=\"dashed\")                 #Rodrigazo\n",
    "plt.text(1975,0,\"Rodrigazo\",fontsize=20,color=\"black\",rotation=90)\n",
    "plt.axvline(1976,color=\"grey\",linewidth=4,linestyle=\"dashed\")                 #Dictadura\n",
    "plt.text(1976,0,\"Dictadura\",fontsize=20,color=\"black\",rotation=90)\n",
    "plt.axvline(1978,color=\"grey\",linewidth=4,linestyle=\"dashed\")               #Mundial\n",
    "plt.text(1978,0,\"Mundial\",fontsize=20,color=\"black\",rotation=90)\n",
    "plt.axvline(1982,color=\"grey\",linewidth=4,linestyle=\"dashed\")                 #Guerra de las Malvinas\n",
    "plt.text(1982,0,\"Guerra de las Malvinas\",fontsize=20,color=\"black\",rotation=90)       \n",
    "plt.axvline(1983,color=\"grey\",linewidth=4,linestyle=\"dashed\")               #Vuelta de la democracia\n",
    "plt.text(1983,0,\"Vuelta de la Democracia\",fontsize=20,color=\"black\",rotation=90)      \n",
    "plt.axvline(1989,color=\"grey\",linewidth=4,linestyle=\"dashed\")                 #Hiperinflación\n",
    "plt.text(1989,0,\"Hiperinflación\",fontsize=20,color=\"black\",rotation=90)               \n",
    "#plt.axvline(2001,color=\"grey\",linewidth=4,linestyle=\"dashed\")                 #Crisis del 2001\n",
    "#plt.text(2001,0,\"Crisis 2001\",fontsize=20,color=\"black\",rotation=90)                  \n",
    "plt.title(\"Topicos desde %s\" % desde + \" hasta %s\" % hasta,fontsize=35)\n",
    "plt.xlabel(\"Fecha de edición\", fontsize=20)\n",
    "plt.ylabel(\"# Canciones\", fontsize=20)\n",
    "plt.xlim(desde,hasta)\n",
    "plt.xticks(ticks=range(desde,hasta),fontsize=20,rotation=90)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.legend(fontsize=25,loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentimientos\n",
    "Decadas 1970-1990s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desde = 1970 ; hasta = 1990\n",
    "df_final.loc[df_final[\"Decada\"].isin(range(desde,hasta)) & df_final[\"Sentimiento\"].isin(['Positivo','Negativo'])].pivot_table(index='Fecha_edicion',columns='Sentimiento',values='Liricas',aggfunc=len, fill_value=0).plot(figsize=(30,10))\n",
    "#Hitos históricos de la Argentia\n",
    "plt.axvline(1975,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Rodrigazo\n",
    "plt.text(1975,0,\"Rodrigazo\",fontsize=20,color=\"black\",rotation=90)\n",
    "plt.axvline(1976,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Dictadura\n",
    "plt.text(1976,0,\"Dictadura\",fontsize=20,color=\"black\",rotation=90)\n",
    "plt.axvline(1978,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Mundial\n",
    "plt.text(1978,0,\"Mundial\",fontsize=20,color=\"black\",rotation=90)\n",
    "plt.axvline(1982,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Guerra de las Malvinas\n",
    "plt.text(1982,0,\"Guerra de las Malvinas\",fontsize=20,color=\"black\",rotation=90)       \n",
    "plt.axvline(1983,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Vuelta de la democracia\n",
    "plt.text(1983,0,\"Vuelta de la Democracia\",fontsize=20,color=\"black\",rotation=90)      \n",
    "plt.axvline(1989,color=\"grey\",linewidth=4,linestyle=\"dashed\")           # Hiperinflación\n",
    "plt.text(1989,0,\"Hiperinflación\",fontsize=20,color=\"black\",rotation=90)               \n",
    "#plt.axvline(2001,color=\"grey\",linewidth=4,linestyle=\"dashed\")          # Crisis del 2001\n",
    "#plt.text(2001,0,\"Crisis 2001\",fontsize=20,color=\"black\",rotation=90)                  \n",
    "plt.title(\"Sentimientos desde %s\" % desde + \" hasta %s\" % hasta,fontsize=35)\n",
    "plt.xlabel(\"Fecha de edición\", fontsize=20)\n",
    "plt.ylabel(\"# Canciones\", fontsize=20)\n",
    "plt.xlim(desde,hasta)\n",
    "plt.xticks(ticks=range(desde,hasta),fontsize=20,rotation=90)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.legend(fontsize=25,loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
